# -*- coding: utf-8 -*-
"""NLP.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1D1Tbh17-4OV_-voJ1w9zY9EsAdZ-bTZV

# Spotify Review Sentiment Analysis

**Features/Columns**: The dataset consists of review texts as the primary feature and corresponding sentiment labels. The review text captures user feedback on Spotify, while the sentiment labels categorize the nature of the reviews.

**Sentiment Labels**: The sentiment labels are binary, indicating whether a review is positive or negative. This classification helps in understanding overall user sentiment towards Spotify.

This dataset serves as an ideal foundation for building a sentiment analysis model, allowing the classification of user opinions and enhancing understanding of customer feedback.
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import nltk
from nltk.stem.porter import PorterStemmer
nltk.download('stopwords')
from nltk.corpus import stopwords
STOPWORDS = set(stopwords.words('english'))

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.model_selection import cross_val_score
from sklearn.metrics import confusion_matrix, classification_report, accuracy_score,ConfusionMatrixDisplay
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import GridSearchCV
from sklearn.model_selection import StratifiedKFold
from wordcloud import WordCloud
from sklearn.tree import DecisionTreeClassifier
import pickle
import re

# Commented out IPython magic to ensure Python compatibility.
# %pip install wordcloud

# load data

data = pd.read_csv('/content/drive/MyDrive/Datascience/project/NLP project/DATASET.csv')
data.head()

"""# **Exploratory Data Analysis**"""

data.shape

data.describe

data.info()

data.isnull().sum()

data.duplicated().sum()

data.drop_duplicates(inplace=True)

# Creating a new column 'length' that will contain the length of the string in 'Review' column
data['length'] = data['Review'].apply(len)

data.columns

for i in data.columns:
  print(i)
  print(data[i].value_counts())
  print('*'*100)
  print(data[i].unique())

# Barplot to visualize the total counts of each label

plt.figure(figsize=(8,6))
sns.countplot(data=data,x='label',palette='plasma',edgecolor='black',linewidth=1)
plt.xlabel('Label')
plt.ylabel('Total counts')
plt.title('Total counts of each label')
plt.show()

# percentage distribution of label

data['label'].value_counts(normalize=True)*100

# create pie chart based on percentage of label

plt.figure(figsize=(8,6))
plt.pie(data['label'].value_counts(),labels=data['label'].value_counts().index,autopct='%1.2f%%',colors=sns.color_palette('plasma'),wedgeprops=dict(width=0.5))
plt.title('Percentage distribution of label')
plt.show()

data['length'].describe()

sns.histplot(data['length'],color='blue',edgecolor='black',linewidth=1)
plt.xlabel('Length')
plt.ylabel('Frequency')
plt.title('Distribution of length of Review')
plt.show()

# To take text data and convert it into matrix token of counts
cv = CountVectorizer(stop_words='english')
words = cv.fit_transform(data.Review)

#Combine all reviews
reviews = " ".join([review for review in data['Review']])

#Initialize wordcloud object
wc = WordCloud(background_color="white", width=800, height=600)

#Generate and plot wordcloud
plt.figure(figsize=(10, 8))
plt.imshow(wc.generate(reviews))
plt.axis("off")
plt.show()

"""# **Processing and Modelling**

To build the corpus from the 'Review'
   1. Replace any non alphabet character with a space
   2. Covert to lower case and split into words
   3. Iterate over the individual words and if it is not a stopwords then add the stemmed(A technique to remove the suffixes from english words and obtain their stems) form of the word to the corpus.
"""

corpus = []
stemmer = PorterStemmer()

for i in range(0, data.shape[0]):
  review = re.sub('[^a-zA-Z]', ' ', data.iloc[i]['Review'])
  review = review.lower()
  review = review.split()
  review = [stemmer.stem(word) for word in review if not word in STOPWORDS]
  review = ' '.join(review)
  corpus.append(review)

data = data.dropna(subset=['label'])

#storing independent and dependent variable in X and Y.

x = pd.DataFrame({'tweet':corpus})
y = data['label']

# checking the shape of x and y
x.shape

y.shape

"""Spliting data into train and test with 30% data with testing."""

x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.3,random_state=15)

print("x_train : ", (x_train.shape))
print("x_test : ", {x_test.shape})
print("y_train : ", {y_train.shape})
print("y_test : ", {y_test.shape})

vectorizer = TfidfVectorizer()

x_train_vec = vectorizer.fit_transform(x_train['tweet'])
x_test_vec = vectorizer.transform(x_test['tweet'])

#scaling x_train and x_test
scaler = StandardScaler()
x_train_scaled = scaler.fit_transform(x_train_vec.toarray()) # Convert to dense array if necessary
x_test_scaled = scaler.transform(x_test_vec.toarray())

"""RANDOM FOREST MODEL"""

model_random = RandomForestClassifier()
model_random.fit(x_train_scaled,y_train)

y_pred = model_random.predict(x_test_scaled)

"""Evaluating model"""

print("Training_score: ",model_random.score(x_train_scaled,y_train))
print("Testing_score: ",model_random.score(x_test_scaled,y_test))

accuracy_random = accuracy_score(y_test,y_pred)
print("Accuracy: ",accuracy_random)

con_metrics = confusion_matrix(y_test,y_pred)
print(con_metrics)

cm_display = ConfusionMatrixDisplay(con_metrics,display_labels=[False,True])
cm_display.plot(cmap='Blues')
plt.show()

print("classification report \n",classification_report(y_test,y_pred))

"""cross validation"""

accuracies = cross_val_score(estimator=model_random,X=x_train_scaled,y=y_train,cv=10)

print("Accuracy : ",accuracies.mean())
print("Standard Deviation : ",accuracies.std())

accuracies

"""Applying grid search to get optimal parameters on random forest"""

params = {
    'bootstrap' : [True],
    'max_depth' : [90,100],
    'min_samples_split' : [8,12],
    'n_estimators' : [100,300]

}

cv_object = StratifiedKFold(n_splits=2)

grid_search = GridSearchCV(estimator = model_random,param_grid=params,cv=cv_object,verbose=0,return_train_score=True)
grid_search.fit(x_train_scaled,y_train)

#getting the best parameters from grid search

print("Best parameter combination : {}",format(grid_search.best_params_))

print("Cross validation mean accuracy on train set  : ",format(grid_search.cv_results_['mean_train_score'].mean()*100))
print("Cross validation mean accuracy on test set  : ",format(grid_search.cv_results_['mean_test_score'].mean()*100))
print("Accuracy score for test set : ",accuracy_score(y_test,y_pred))

"""Logistic regression model"""

from sklearn.linear_model import LogisticRegression
model_logistic = LogisticRegression()
model_logistic.fit(x_train_scaled,y_train)

y_pred1 = model_logistic.predict(x_test_scaled)

"""Evaluation"""

accuracy_logistic = accuracy_score(y_test,y_pred1)
print("Accuracy: ",accuracy_logistic)

con_metrics_logi = confusion_matrix(y_test,y_pred1)
print(con_metrics_logi)

cm_display_logistic = ConfusionMatrixDisplay(con_metrics_logi,display_labels=[False,True])
cm_display_logistic.plot()
plt.show()

"""Decision Tree model"""

model_dc = DecisionTreeClassifier()
model_dc.fit(x_train_scaled,y_train)

y_pred2 = model_dc.predict(x_test_scaled)

#plotting tree
from sklearn import tree
plt.figure(figsize=(15,10))
tree.plot_tree(model_dc,filled=True)
plt.show()

"""Evaluation of model"""

print("Training Score ",model_dc.score(x_train_scaled,y_train))
print("Testing Score ",model_dc.score(x_test_scaled,y_test))

accuracy_dc = accuracy_score(y_test,y_pred2)
print("Accuracy: ",accuracy_dc)

conf_dc = confusion_matrix(y_test,y_pred2)
print(conf_dc)

"""Comparing Each models based on accuracy"""

# creat a visualization for comparing accuracy of data
plt.figure(figsize=(8, 6))
# Removed palette='plasma'
plt.bar(['Random Forest', 'Logistic Regression', 'Decision Tree'], [accuracies.mean(), accuracy_logistic, accuracy_dc], color=['blue', 'green', 'red'], edgecolor='black', linewidth=1)
plt.xlabel('Models')
plt.ylabel('Accuracy')
plt.title('Accuracy Comparison')
plt.show()

# comparing using visualization of training score of each models
plt.figure(figsize=(8, 6))
plt.bar(['Random Forest', 'Logistic Regression', 'Decision Tree'], [model_random.score(x_train_scaled,y_train), model_logistic.score(x_train_scaled,y_train), model_dc.score(x_train_scaled,y_train)], color=['blue', 'green', 'red'], edgecolor='black', linewidth=1)
plt.xlabel('Models')
plt.ylabel('Score')
plt.title('Training Score Comparison')
plt.show()

"""**New review prediction using Random forest model**"""

sample = 'Spotify is one of the best apps for streaming music. It lets you listen to your favorite songs, discover new ones, and create playlists. You can use it for free with ads or pay for Premium to enjoy music without ads, download songs, and get better sound quality. Itâ€™s easy to use and has a huge collection of songs, podcasts, and playlists for any mood or activity.'

result = model_random.predict(vectorizer.transform([sample]))
if result == 0:
  print("Negative")
else:
  print("Positive")

"""# **Conclusion**

In the NLP project on Spotify review sentiment analysis, the **Random Forest** model demonstrated superior performance with an accuracy of **85.04%**, outperforming Logistic Regression and Decision Tree models.

This indicates that Random Forest effectively captures complex patterns and interactions within the dataset, making it the most reliable choice for this task.

Logistic Regression is also a strong candidate. Decision Tree might not perform as well as the other two models but could still be useful depending on interpretability needs or specific use cases.
"""



